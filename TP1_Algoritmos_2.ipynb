{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP1 - Algoritmos 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TP1 - Aplicações de algoritmos geométricos"
      ],
      "metadata": {
        "id": "rm6a4t9GDr6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse projeto está em um repositório do Github e pode ser acessado pelo seguinte link:\n",
        "\n",
        "[Kd-three-nearest-neigbour](https://github.com/giulianopenido/kd-three-nearest-neighbour)\n",
        "\n",
        "No repositório estão salvos todos os datasets utilizados nos testes."
      ],
      "metadata": {
        "id": "lYE7BCw7obKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliotecas utilizadas"
      ],
      "metadata": {
        "id": "VhSIuUhDDzmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizou-se a biblioteca numpy para realizar a leitura dos arquivos CSV e para executar operações vetoriais na base de dados."
      ],
      "metadata": {
        "id": "k7F8N1aDD4SF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "eTNPgkNBar8h"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizou-se a biblioteca heapq, que implementa a estrutura de dados heap de prioridade, que funciona analogamente à uma fila de prioridade, porém em formato de heap. A decisão de utilizar essa biblioteca ao invés de prover uma implementação própria dessa estrutura deve-se ao fato de ela existe na biblioteca STL de C++ e, portanto, poderia ser utilizada, de acordo com a especificação do trabalho."
      ],
      "metadata": {
        "id": "oy_6IAlvD50t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq"
      ],
      "metadata": {
        "id": "cKmOSoBaD5Nr"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções auxiliares"
      ],
      "metadata": {
        "id": "xz62a8QLGbRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função utilizada na leitura dos dados a partir de um arquivo CSV e na divisão do dataset em base de treino e base de testes. Observe que o caminho para o arquivo deve ser passado via parâmetro, assim como o percentual de divisão dos dados e a semente de aleatoriedade"
      ],
      "metadata": {
        "id": "INEgmQ6-GgPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datasets_from_file(filepath, train_size = 0.7, seed = 42):\n",
        "  dataset = np.unique(np.genfromtxt(filepath, delimiter = ','), axis=0)\n",
        "  num_train_instances = int(len(dataset) * train_size)\n",
        "  if(seed is not None):\n",
        "    np.random.seed(seed)\n",
        "  np.random.shuffle(dataset)\n",
        "  train_set, test_set = dataset[:num_train_instances], dataset[num_train_instances:]\n",
        "  return (train_set, test_set)"
      ],
      "metadata": {
        "id": "HCyU6_07p4lF"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função que computa a distância euclidiana entre dois pontos"
      ],
      "metadata": {
        "id": "Cx-6V-MWNzNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_distance(p1, p2):\n",
        "  return np.sqrt(np.sum(np.square(p1 - p2)))"
      ],
      "metadata": {
        "id": "yaBzQHfFkbwO"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kd Tree"
      ],
      "metadata": {
        "id": "89CQibsGl6EJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classe que representa um nó de árvore. Possui um atributo correspondente ao ponto cartesiano que armazena e um atributo para cada um de seus ramos (esquerdo e direito)."
      ],
      "metadata": {
        "id": "B9Z6uR2TzxjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, left_node, right_node, point):\n",
        "    self.left_node = left_node\n",
        "    self.right_node = right_node\n",
        "    self.point = point\n",
        "\n",
        "  def is_leaf(self):\n",
        "    return self.left_node == None and self.right_node == None"
      ],
      "metadata": {
        "id": "ayEyuIsMzouz"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classe correspondente à árvore KDTree, construída recursivamente. \n",
        "\n",
        "O processo de construção da árvore funciona da seguinte forma: O dataset é ordenado conforme a coordenada que será levada em conta no nível da árvore a ser construído. Depois de ordenado, ele é dividido no seu ponto de mediana e cria-se um nó com ele. Em sequência, executa-se o mesmo procedimento com cada uma das subpartições geradas da divisão, até que os datasets sejam indivisíveis(Um único ponto). Nessa situação, cria-se uma folha com o ponto restante. \n",
        "\n",
        "Observe que o Heapsort foi utilizado como método de ordenação na etapa de selecionar a mediana do dataset. Essa opção no projeto deve-se ao fato de que era necessário economizar memória auxiliar, dado que o algoritmo de construção da árvore demanda muita memória.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q6YJ_Jfh0B5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A classe KDTree também implementa o método de encontrar os K vizinhos mais próximos. Esse método funciona da seguinte forma:\n",
        "A árvore é percorrida recursivamente, porém, apenas os ramos em que há chances de existir um vizinho próximo são acessados. À medida que percorre-se a árvore,  são selecionados pontos com base nas menores distâncias em relação ao ponto em análise. Os selecionados são armazenados em um Heap de prioridade (Estrutura de dados que prioriza os pontos cuja distância em relação ao ponto em análise está entre as menores). Ao final da execução, os pontos presentes no heap serão os K pontos mais próximos."
      ],
      "metadata": {
        "id": "fjxxuhIvL3W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Kd_tree:\n",
        "  def __init__(self, dataset, ndim):\n",
        "    self.ndim = ndim\n",
        "    self.root = self.build_kd_tree(dataset)\n",
        "\n",
        "  def build_kd_tree(self, dataset, depth=0):\n",
        "    dataset_size = len(dataset)\n",
        "    current_dimension = (depth) % self.ndim\n",
        "    dataset = dataset[np.argsort(dataset[:, current_dimension], kind='heapsort')]\n",
        "    if(dataset_size == 0):\n",
        "      return None\n",
        "    elif(dataset_size == 1):\n",
        "      return Node(None, None, dataset[0])\n",
        "    else:\n",
        "      half = dataset_size // 2\n",
        "      left = self.build_kd_tree(dataset[: half], depth+1)\n",
        "      right = self.build_kd_tree(dataset[half:], depth+1)\n",
        "      return Node(left, right, dataset[half]) \n",
        "\n",
        "  def recursive_k_nearest(self, k, current_node, point, priority_heap, depth=0):\n",
        "    if(current_node == None):\n",
        "      return\n",
        "\n",
        "    current_dimension = depth % self.ndim\n",
        "    distance = get_distance(point[:self.ndim], current_node.point[:self.ndim])\n",
        "\n",
        "    if(len(priority_heap) < k and current_node.is_leaf()):\n",
        "      try:\n",
        "        heapq.heappush(priority_heap, (-distance, current_node.point))\n",
        "      except ValueError: pass\n",
        "    elif(current_node.is_leaf() and distance < abs(priority_heap[0][0])):\n",
        "      try:\n",
        "        heapq.heappushpop(priority_heap, (-distance, current_node.point))\n",
        "      except ValueError: pass\n",
        "    next_branch, other_branch = None, None\n",
        "\n",
        "    if(point[current_dimension] < current_node.point[current_dimension]):\n",
        "      next_branch, other_branch = current_node.left_node, current_node.right_node\n",
        "    else: \n",
        "      next_branch, other_branch = current_node.right_node, current_node.left_node\n",
        "\n",
        "    self.recursive_k_nearest(k, next_branch, point, priority_heap, depth+1)\n",
        "    line_shortest_distance = abs(point[current_dimension] - current_node.point[current_dimension])\n",
        "    if(abs(priority_heap[0][0]) > line_shortest_distance or len(priority_heap) < k ):\n",
        "      self.recursive_k_nearest(k, other_branch, point, priority_heap, depth+1)\n",
        "\n",
        "  def get_k_nearest(self, k, point):\n",
        "    heap = []\n",
        "    self.recursive_k_nearest(k, self.root, point, heap)\n",
        "    return heap\n",
        "\n",
        "  def get_three_structure(self, current_node, depth = 0):\n",
        "    print(current_node.point, depth)\n",
        "    if(current_node == None):\n",
        "      return\n",
        "    if(current_node.right_node == None and current_node.left_node == None):\n",
        "      print(f'{depth}: {current_node.point}')\n",
        "    else:\n",
        "      self.get_three_structure(current_node.left_node, depth+1)\n",
        "      self.get_three_structure(current_node.right_node, depth+1)\n",
        "\n",
        "  def print_three(self):\n",
        "    self.get_three_structure(self.root)"
      ],
      "metadata": {
        "id": "Pq6RuvSid7Yq"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN Classifier"
      ],
      "metadata": {
        "id": "32yX9szrTLEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A classe K_neighbours_classifier é uma abstração do uso da Kd Tree na busca pelos vizinhos próximos, tendo em vista que ela simplifica o uso do algoritmo por meio de funções simples e que são comuns a qualquer modelo de classificação. \n",
        "Observe que a função fit, que constrói a árvore, recebe como parâmetro o número de atributos do dataset. Esse valor é necessário para realizar a divisão dos dados entre atributos e classes.\n",
        "A função predict, por sua vez, recebe o conjunto a partir do qual será realizada uma previsão e retorna as classes para as quais os pontos foram classificados."
      ],
      "metadata": {
        "id": "ML3vPGnMQZk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class K_neighbours_classifier:\n",
        "  def __init__(self, k = 2):\n",
        "    self.k = k\n",
        "  \n",
        "  def fit(self, dataset, num_of_features):\n",
        "    self.kd_tree = Kd_tree(dataset, num_of_features)\n",
        "\n",
        "  def predict(self, points):\n",
        "    predictions = []\n",
        "    for point in points:\n",
        "      knn_heap = self.kd_tree.get_k_nearest(self.k, np.array(point))\n",
        "      frequencies = {}\n",
        "      for near_point_data in knn_heap:\n",
        "        distance, near_point = near_point_data\n",
        "        near_point_class = near_point[-1]\n",
        "        if near_point_class in frequencies:\n",
        "            frequencies[near_point_class] += 1\n",
        "        else:\n",
        "            frequencies[near_point_class] = 1\n",
        "      classes_ordered_by_frequency = sorted(frequencies.items(), key = lambda x: x[1], reverse=True)\n",
        "      predictions.append(classes_ordered_by_frequency[0][0])\n",
        "    return np.array(predictions)\n",
        "    \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "8h2kpjusgmoY"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A classe Metrics engloba algumas funções comuns de avaliação de modelos de classificação. Para o seu uso, é necessário instanciá-la passando no construtor os rótulos do dataset de teste e as predições do modelo."
      ],
      "metadata": {
        "id": "rPnxAr8aSZpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics:\n",
        "  def __init__(self, test_labels, predictions):\n",
        "    self.test_labels = test_labels\n",
        "    self.predictions = predictions\n",
        "\n",
        "  def get_most_frequent_category(self):\n",
        "    frequencies = {}\n",
        "    for prediction in self.predictions:\n",
        "      if prediction in frequencies:\n",
        "        frequencies[prediction] += 1\n",
        "      else:\n",
        "        frequencies[prediction] = 1\n",
        "    return sorted(frequencies.items(), key = lambda x: x[1], reverse=True)[0][0]\n",
        "\n",
        "  def get_accuracy(self):\n",
        "    correct_predictions = 0\n",
        "    for value, prediction in zip(self.test_labels, self.predictions):\n",
        "      if(value == prediction):\n",
        "        correct_predictions += 1\n",
        "\n",
        "    return correct_predictions/len(self.predictions)\n",
        "\n",
        "  def get_precision(self):\n",
        "    most_frequent_cat = self.get_most_frequent_category()\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    for value, prediction in zip(self.test_labels, self.predictions):\n",
        "      if(value == prediction and prediction == most_frequent_cat):\n",
        "        true_positives += 1\n",
        "      elif(value != most_frequent_cat and prediction == most_frequent_cat):\n",
        "        false_positives += 1\n",
        "\n",
        "    return true_positives/(true_positives + false_positives)\n",
        "\n",
        "  def get_recall(self):\n",
        "    most_frequent_cat = self.get_most_frequent_category()\n",
        "    true_positives = 0\n",
        "    false_negatives = 0\n",
        "    for value, prediction in zip(self.test_labels, self.predictions):\n",
        "      if(value == prediction and prediction == most_frequent_cat):\n",
        "        true_positives += 1\n",
        "      elif(value == most_frequent_cat and prediction != most_frequent_cat):\n",
        "        false_negatives += 1\n",
        "\n",
        "    return true_positives/(true_positives + false_negatives)\n",
        "\n",
        "  def get_statistics(self):\n",
        "    print(f\"\"\"\n",
        "    Acurácia: { self.get_accuracy() }\n",
        "    Precisão: { self.get_precision() }\n",
        "    Revocação: { self.get_recall() }\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "qNcyidqg364R"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Casos de uso do modelo"
      ],
      "metadata": {
        "id": "_06WAvfCTSz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para testar os algoritmos e estruturas de dados implementados, utilizou-se 10 datasets diferentes e as estatísticas das previsões do modelo foram computadas, conforme consta abaixo:"
      ],
      "metadata": {
        "id": "fPejuPXwoBUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of datasets --> Tuple of (path, num_of_features) \n",
        "datasets = [\n",
        "  ('datasets/banana.csv', 2),\n",
        "  ('datasets/appendicitis.csv', 7),\n",
        "  ('datasets/bupa.csv', 6),\n",
        "  ('datasets/haberman.csv', 3),\n",
        "  ('datasets/monk-2.csv', 6),\n",
        "  ('datasets/phoneme.csv', 5),\n",
        "  ('datasets/pima.csv', 8),\n",
        "  ('datasets/saheart.csv', 9),\n",
        "  ('datasets/magic.csv', 10),\n",
        "]"
      ],
      "metadata": {
        "id": "4u14yt-dStNn"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset, num_of_features in datasets:\n",
        "  print(f\"-------- DATASET : {dataset} ----------\")\n",
        "  train_set, test_set = get_datasets_from_file(dataset)\n",
        "  knn_classifier = K_neighbours_classifier(7)\n",
        "  knn_classifier.fit(train_set, num_of_features)\n",
        "  predictions = knn_classifier.predict(test_set)\n",
        "  print(\"Avaliação do modelo: \")\n",
        "  Metrics(test_set[:, -1], predictions).get_statistics()\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJi0c6sxT3eg",
        "outputId": "6dcb0722-fade-4062-aac1-ade5733d6bdf"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------- DATASET : datasets/banana.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.896095717884131\n",
            "    Precisão: 0.8982494529540481\n",
            "    Revocação: 0.9193729003359462\n",
            "    \n",
            "\n",
            "\n",
            "-------- DATASET : datasets/appendicitis.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.9393939393939394\n",
            "    Precisão: 0.967741935483871\n",
            "    Revocação: 0.967741935483871\n",
            "    \n",
            "\n",
            "\n",
            "-------- DATASET : datasets/bupa.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.6310679611650486\n",
            "    Precisão: 0.6282051282051282\n",
            "    Revocação: 0.8596491228070176\n",
            "    \n",
            "\n",
            "\n",
            "-------- DATASET : datasets/haberman.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.7325581395348837\n",
            "    Precisão: 0.75\n",
            "    Revocação: 0.9344262295081968\n",
            "    \n",
            "\n",
            "\n",
            "-------- DATASET : datasets/monk-2.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.8076923076923077\n",
            "    Precisão: 0.7402597402597403\n",
            "    Revocação: 0.9193548387096774\n",
            "    \n",
            "\n",
            "\n",
            "-------- DATASET : datasets/phoneme.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.863013698630137\n",
            "    Precisão: 0.8948275862068965\n",
            "    Revocação: 0.9137323943661971\n",
            "    \n",
            "\n",
            "\n",
            "-------- DATASET : datasets/pima.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.7532467532467533\n",
            "    Precisão: 0.7818181818181819\n",
            "    Revocação: 0.86\n",
            "    \n",
            "\n",
            "\n",
            "-------- DATASET : datasets/saheart.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.6258992805755396\n",
            "    Precisão: 0.711340206185567\n",
            "    Revocação: 0.75\n",
            "    \n",
            "\n",
            "\n",
            "-------- DATASET : datasets/magic.csv ----------\n",
            "Avaliação do modelo: \n",
            "\n",
            "    Acurácia: 0.8087094499294781\n",
            "    Precisão: 0.8000933053417308\n",
            "    Revocação: 0.9379272627837025\n",
            "    \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}